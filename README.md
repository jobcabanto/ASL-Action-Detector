# ASL Action Detector

The objective of this project was to get a feel for image recognition and deep learning/neural network concepts with American Sign Language. Essentially what the program does is it takes real-time video and makes predictions from the following of what I'm really trying to sign:
- "Hello"
- "Thank You"
- "I Love You"

Tools/Technologies Used:
- Python
- Tensorflow
- Scikit-learn
- NumPy
- Pandas
- OpenCV
- MediaPipe

This project was completed with Nicholas Renotte's YouTube Tutorial: 
https://www.youtube.com/watch?v=doDUihpj6ro&list=LL&index=2&t=3964s

![alt text](https://github.com/jobcabanto/ASL-Action-Detector/blob/main/res/asl_visual2.png)
