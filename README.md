# ASL Action Detector

The objective on this project was to get a feel for image recognition and deep learning/neural network concepts with the use sign language. Essentially what the program does is take real-time video predicting whether I am trying to sign:
- "Hello"
- "Thank You"
- "I Love You"

Tools/Technologies Used:
- Python
- Tensorflow
- Scikit-learn
- NumPy
- Pandas
- OpenCV
- MediaPipe

This project was completed with Nicholas Renotte's YouTube Tutorial: https://www.youtube.com/watch?v=doDUihpj6ro&list=LL&index=2&t=3964s

![alt text](https://github.com/jobcabanto/ASL-Action-Detector/blob/main/res/asl_visual2.png)
